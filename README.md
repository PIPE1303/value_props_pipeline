# Value Props Ranking Pipeline

Pipeline de ingenierÃ­a de datos para el ranking de value propositions basado en comportamiento de usuarios.

## Estructura del Proyecto

```
value-prop-ranking-pipeline/
â”œâ”€â”€ data/                   # Datos fuente (no modificar)
â”‚   â”œâ”€â”€ prints.json
â”‚   â”œâ”€â”€ taps.json
â”‚   â””â”€â”€ pays.csv
â”œâ”€â”€ src/                    # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py          # ConfiguraciÃ³n del proyecto
â”‚   â”œâ”€â”€ io_utils.py        # Utilidades de I/O
â”‚   â”œâ”€â”€ feature_engineering.py  # IngenierÃ­a de features
â”‚   â”œâ”€â”€ pipeline.py        # Pipeline principal (Pandas)
â”‚   â”œâ”€â”€ spark_pipeline.py  # Pipeline alternativo (Spark)
â”‚   â””â”€â”€ utils.py           # Utilidades generales
â”œâ”€â”€ scripts/               # Scripts de ejecuciÃ³n
â”‚   â”œâ”€â”€ run_spark_pipeline.py
â”‚   â””â”€â”€ compare_pipelines.py
â”œâ”€â”€ tests/                 # Tests unitarios
â”‚   â”œâ”€â”€ test_pipeline.py
â”‚   â””â”€â”€ test_features.py
â”œâ”€â”€ notebooks/             # Notebooks de exploraciÃ³n
â”‚   â”œâ”€â”€ pipeline_pandas.py
â”‚   â””â”€â”€ pipeline_pyspark.py
â”œâ”€â”€ output/                # Resultados generados
â”œâ”€â”€ logs/                  # Logs de ejecuciÃ³n
â”œâ”€â”€ models/                # Modelos entrenados (futuro)
â”œâ”€â”€ main.py               # Script principal
â”œâ”€â”€ requirements.txt      # Dependencias
â””â”€â”€ README.md
```

## InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd value-prop-ranking-pipeline
```

2. **Crear entorno virtual:**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias:**
```bash
pip install -r requirements.txt
```

## Uso

### Pipeline Principal (Pandas)

```bash
python main.py
```

### Pipeline Spark (para datasets grandes)

```bash
python scripts/run_spark_pipeline.py
```

### Comparar resultados

```bash
python scripts/compare_pipelines.py
```

### Ejecutar tests

```bash
pytest tests/
```

## ðŸ”§ ConfiguraciÃ³n

El archivo `src/config.py` contiene todas las configuraciones del proyecto:

- **Rutas de datos**: UbicaciÃ³n de archivos fuente
- **Ventanas temporales**: ConfiguraciÃ³n de anÃ¡lisis histÃ³rico
- **ConfiguraciÃ³n Spark**: ParÃ¡metros para procesamiento distribuido
- **Columnas finales**: Esquema del dataset de salida

## Features Generadas

El pipeline genera las siguientes features:

| Feature | DescripciÃ³n |
|---------|-------------|
| `user_id` | Identificador Ãºnico del usuario |
| `value_prop_id` | Identificador de la value proposition |
| `timestamp` | Timestamp del evento |
| `clicked` | Flag binario (1 si hubo click, 0 si no) |
| `print_count_3w` | NÃºmero de prints en las Ãºltimas 3 semanas |
| `tap_count_3w` | NÃºmero de taps en las Ãºltimas 3 semanas |
| `pay_count_3w` | NÃºmero de pagos en las Ãºltimas 3 semanas |
| `total_amount_3w` | Monto total pagado en las Ãºltimas 3 semanas |

## Validaciones

El pipeline incluye mÃºltiples validaciones:

- **ValidaciÃ³n de esquema**: Verifica que los datos tengan la estructura esperada
- **ValidaciÃ³n de calidad**: Detecta valores faltantes y anomalÃ­as
- **ValidaciÃ³n de integridad**: Asegura consistencia entre datasets
- **ValidaciÃ³n de rangos**: Verifica que las fechas y valores numÃ©ricos sean vÃ¡lidos

## Reportes

El pipeline genera automÃ¡ticamente:

- **Dataset final**: CSV con todas las features
- **Reporte resumen**: EstadÃ­sticas descriptivas
- **Metadatos**: InformaciÃ³n del procesamiento
- **Logs**: Trazabilidad completa del proceso

## Testing

```bash
# Ejecutar todos los tests
pytest

# Ejecutar tests especÃ­ficos
pytest tests/test_pipeline.py

# Con cobertura
pytest --cov=src tests/
```

## Pipeline de Datos

### 1. Carga de Datos
- **Prints**: Eventos de visualizaciÃ³n de value propositions
- **Taps**: Eventos de click en value propositions  
- **Pays**: Eventos de pago asociados a value propositions

### 2. Procesamiento
- **Limpieza**: ValidaciÃ³n y correcciÃ³n de datos
- **Feature Engineering**: CreaciÃ³n de features histÃ³ricas
- **AgregaciÃ³n**: CÃ¡lculo de mÃ©tricas por usuario y value prop

### 3. ValidaciÃ³n
- **Calidad**: VerificaciÃ³n de integridad de datos
- **Consistencia**: ValidaciÃ³n de rangos y tipos
- **Completitud**: VerificaciÃ³n de valores faltantes

### 4. Salida
- **Dataset final**: CSV listo para modelado
- **Reportes**: DocumentaciÃ³n del procesamiento
- **Logs**: Trazabilidad del proceso

## Optimizaciones

### Pandas (Recomendado para datasets < 10GB)
- Procesamiento en memoria
- Optimizado para velocidad
- FÃ¡cil debugging y desarrollo

### Spark (Recomendado para datasets > 10GB)
- Procesamiento distribuido
- Escalabilidad horizontal
- Manejo de memoria eficiente

## Logs

Los logs se guardan en `logs/` y `output/` con diferentes niveles:

- **INFO**: Progreso del pipeline
- **WARNING**: Problemas no crÃ­ticos
- **ERROR**: Errores que requieren atenciÃ³n
- **DEBUG**: InformaciÃ³n detallada para debugging

## ContribuciÃ³n

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## Soporte

Para reportar bugs o solicitar features, por favor crear un issue en el repositorio.

## DocumentaciÃ³n Adicional

- [GuÃ­a de ConfiguraciÃ³n](docs/CONFIGURATION.md)
- [API Reference](docs/API.md)
- [Troubleshooting](docs/TROUBLESHOOTING.md)

---
